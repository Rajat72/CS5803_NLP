{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "## Roll Number : CS25MTECH02007\n",
    "## Name : Rajat Maheshwari\n",
    "<hr>\n",
    "\n",
    "# Text Cleaning, and Model Building For Given DataSets\n",
    "\n",
    "## üìù Assignment Overview\n",
    "In this assignment, I will:\n",
    "1. **Implement** 4 different NLP classification models\n",
    "2. **Clean and harmonize**  Given Data for model building\n",
    "3. Perform **text-based Classification** on the cleaned data to extract insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.32.3)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 2))\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (3.8.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (8.1.5)\n",
      "Requirement already satisfied: keras in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (3.8.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: torch in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from requests->-r requirements.txt (line 1)) (2024.12.14)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r requirements.txt (line 2))\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 2))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 3)) (2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 4)) (2025.1)\n",
      "Requirement already satisfied: click in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (0.15.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (2.10.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from spacy->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (1.8.12)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (8.31.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (6.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 8)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 8)) (3.0.13)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from keras->-r requirements.txt (line 9)) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from keras->-r requirements.txt (line 9)) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from keras->-r requirements.txt (line 9)) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from keras->-r requirements.txt (line 9)) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from keras->-r requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from keras->-r requirements.txt (line 9)) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow->-r requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (5.29.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (3.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 7)) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 7)) (308)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 6)) (2.27.2)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 6)) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from rich->keras->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 6)) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (0.45.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->-r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.13)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 10)) (3.1.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\rajat\\onedrive\\documents\\iit h\\sem-1\\nlp\\cs5803_nlp\\venv\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.3)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.1 MB 6.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.1 MB 6.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.1 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.1 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.1 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 7.5 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/40.9 MB 6.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.6/40.9 MB 6.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.7/40.9 MB 6.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.0/40.9 MB 5.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 6.3/40.9 MB 6.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.6/40.9 MB 6.1 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.9/40.9 MB 6.2 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 10.2/40.9 MB 6.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.3/40.9 MB 6.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 12.1/40.9 MB 5.9 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.8/40.9 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.9/40.9 MB 5.6 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.7/40.9 MB 5.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 15.2/40.9 MB 5.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 16.3/40.9 MB 5.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 17.0/40.9 MB 5.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.8/40.9 MB 5.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 18.4/40.9 MB 5.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.9/40.9 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 19.4/40.9 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 20.4/40.9 MB 4.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 21.5/40.9 MB 4.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 22.5/40.9 MB 4.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.6/40.9 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 24.9/40.9 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 26.2/40.9 MB 4.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 27.3/40.9 MB 4.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 28.6/40.9 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 29.6/40.9 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 30.7/40.9 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 31.5/40.9 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 32.5/40.9 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 33.6/40.9 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 34.9/40.9 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 36.2/40.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 37.2/40.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.5/40.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/40.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib\n",
    "import unicodedata\n",
    "import urllib.parse\n",
    "import logging\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\rajat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaner Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner:\n",
    "    def __init__(self):\n",
    "        # Initialize regex patterns directly in __init__\n",
    "        self.json_pattern = re.compile(r'\\{[^}]+\\}', re.DOTALL)\n",
    "        self.math_pattern = re.compile(r'\\$.*?\\$', re.DOTALL)\n",
    "        self.control_chars = re.compile(r\"[\\x00-\\x09\\x0B\\x0C\\x0E-\\x1F\\x7F-\\x9F]\")\n",
    "        self.extra_newlines = re.compile(r'\\n{9,}')\n",
    "        self.game_word = re.compile(r'\\bgame\\b', re.IGNORECASE)\n",
    "        self.non_word_chars = re.compile(r\"[^\\w\\s]\")\n",
    "        self.multi_space = re.compile(r\" +\")\n",
    "\n",
    "        # Initialize NLTK components directly\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def _get_wordnet_pos(self, treebank_tag):\n",
    "        return {\n",
    "            'J': wordnet.ADJ,\n",
    "            'V': wordnet.VERB,\n",
    "            'R': wordnet.ADV\n",
    "        }.get(treebank_tag[0], wordnet.NOUN)\n",
    "\n",
    "    def lemmatize_text(self, text, use_pos=True):\n",
    "        \"\"\"Perform lemmatization with POS tagging\"\"\"\n",
    "        try:\n",
    "            tokens = word_tokenize(text)\n",
    "            if use_pos:\n",
    "                pos_tags = nltk.pos_tag(tokens)\n",
    "                return ' '.join([\n",
    "                    self.lemmatizer.lemmatize(word, self._get_wordnet_pos(tag))\n",
    "                    for word, tag in pos_tags\n",
    "                ])\n",
    "            return ' '.join([self.lemmatizer.lemmatize(word) for word in tokens])\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Lemmatization error: {str(e)}\")\n",
    "            return text\n",
    "\n",
    "    def remove_numbers(self, text):\n",
    "        \"\"\"Remove standalone numbers while preserving alphanumeric terms\"\"\"\n",
    "        # Remove full numeric tokens but keep alphanumerics like 'COVID19'\n",
    "        return re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Enhanced text cleaning pipeline\"\"\"\n",
    "        try:\n",
    "            text = self.control_chars.sub(\" \", text)\n",
    "            text = unicodedata.normalize(\"NFKD\", text)\n",
    "            text = text.replace(\"\\u2022\", \"\\n- \").replace(\"\\xa0\", \" \")\n",
    "            text = self.non_word_chars.sub(\" \", text)\n",
    "            text = text.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "            text = self.game_word.sub(\"\", text)\n",
    "            text = self.extra_newlines.sub(\"\\n\\n\", text)\n",
    "            return self.multi_space.sub(\" \", text).strip()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Cleaning error: {str(e)}\")\n",
    "            return text\n",
    "        \n",
    "    def clean_ratings(self,text):\n",
    "        \"\"\"Replace patterns like 12M/128k with <RATING_COUNT>\"\"\"\n",
    "        return re.sub(r'\\b\\d+[MK]\\b', 'COUNT', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    def clean_durations(text):\n",
    "        \"\"\"Replace Xh Ym patterns with Duration\"\"\"\n",
    "        return re.sub(r'\\b\\d+h\\s\\d+m\\b', 'Duration', text, flags=re.IGNORECASE)\n",
    "\n",
    "    def full_clean(self, text, is_title=False, remove_stopwords=True, \n",
    "                    lemmatize=True, remove_numbers=False,remove_duration=False,remove_rating=False):\n",
    "            \"\"\"\n",
    "            Enhanced pipeline with number removal\n",
    "            Parameters control processing stages\n",
    "            \"\"\"\n",
    "            try:\n",
    "                # Structural cleaning\n",
    "                text = self.json_pattern.sub('', text)\n",
    "                text = self.math_pattern.sub('Mathematical expression', text)\n",
    "                \n",
    "                # Text normalization\n",
    "                text = self.clean_title(text) if is_title else self.clean_text(text)\n",
    "                \n",
    "                # Numerical cleaning\n",
    "                if remove_numbers:\n",
    "                    text = self.remove_numbers(text)\n",
    "                \n",
    "                # Linguistic processing\n",
    "                if remove_stopwords:\n",
    "                    text = ' '.join([word for word in text.split() \n",
    "                                if word.lower() not in self.stop_words])\n",
    "                \n",
    "                if lemmatize:\n",
    "                    text = self.lemmatize_text(text)\n",
    "                \n",
    "                if remove_duration:\n",
    "                    text = self.clean_durations(text)\n",
    "                \n",
    "                if remove_rating:\n",
    "                    text = self.clean_ratings(text)\n",
    "                \n",
    "                return self.multi_space.sub(' ', text).strip()\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Cleaning pipeline error: {str(e)}\")\n",
    "                return text\n",
    "            \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Full pipeline error: {str(e)}\")\n",
    "                return text\n",
    "\n",
    "    def clean_title(self, text):\n",
    "            \"\"\"Specialized title cleaning\"\"\"\n",
    "            cleaned = self.clean_text(text)\n",
    "            cleaned = urllib.parse.unquote(cleaned)\n",
    "            cleaned = re.sub(r\"_+\", \" \", cleaned)\n",
    "            return self.multi_space.sub(\" \", cleaned).strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_excel(\"data\\\\Dataset-1.xlsx\")\n",
    "data1_copy=data1\n",
    "data2=pd.read_excel(\"data\\\\Dataset-2.xlsx\")\n",
    "data2_copy=data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean DataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaner Objects Intialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = TextCleaner()\n",
    "encoder = OneHotEncoder(sparse_output=False,dtype=np.int8,feature_name_combiner=lambda feature, category: str(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_copy.drop(columns=[\"ID\"],inplace=True)\n",
    "\n",
    "data1_copy['ABSTRACT'] = data1['ABSTRACT'].apply(\n",
    "    lambda x: cleaner.full_clean(x, remove_stopwords=True, lemmatize=True)\n",
    ")\n",
    "data1_copy['TITLE'] = data1['TITLE'].apply(\n",
    "    lambda x: cleaner.full_clean(x, remove_stopwords=True, lemmatize=True, is_title=True)\n",
    ")\n",
    "data1_copy.to_excel(\"Intermediate\\\\data1_pass1.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data2_copy.drop(columns=[\"ID\"],inplace=True)\n",
    "\n",
    "# For custom function with parameters\n",
    "\n",
    "data2_copy['Content'] = data2['Content'].apply(\n",
    "    lambda x: cleaner.full_clean(x, remove_stopwords=True, lemmatize=True, remove_numbers=True)\n",
    ")\n",
    "encoded_array = encoder.fit_transform(data2_copy[[\"Domain\"]])\n",
    "new_columns = encoder.get_feature_names_out()\n",
    "data2_copy = pd.concat([\n",
    "    data2_copy.drop(\"Domain\", axis=1),\n",
    "    pd.DataFrame(encoded_array, columns=new_columns)\n",
    "], axis=1)\n",
    "\n",
    "data2_copy.to_excel(\"Intermediate\\\\data2_pass2.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Content', 'Domain'], dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
